{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show, figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lohith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Lohith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gberg_sent_tokens = sent_tokenize(gutenberg.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She',\n",
       " 'was',\n",
       " 'the',\n",
       " 'youngest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " 'daughters',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'affectionate',\n",
       " ',',\n",
       " 'indulgent',\n",
       " 'father',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " ',',\n",
       " 'in',\n",
       " 'consequence',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sister',\n",
       " \"'s\",\n",
       " 'marriage',\n",
       " ',',\n",
       " 'been',\n",
       " 'mistress',\n",
       " 'of',\n",
       " 'his',\n",
       " 'house',\n",
       " 'from',\n",
       " 'a',\n",
       " 'very',\n",
       " 'early',\n",
       " 'period',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(gberg_sent_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a convenient method that handles newlines, as well as tokenizing sentences and words in one shot\n",
    "gberg_sents = gutenberg.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size:vector dimensions(go with doubling the num for trial),sg=1 is skipgram model 0 is CBOW,window=10\n",
    "# means how many context words to be considered on left and right of target word, \n",
    "# iter means how many iterions to be used def is 5\n",
    "# min_count means min num of times a word needs to occur to fit into word2vec space, workers is num of cores in sym\n",
    "model = Word2Vec(sentences=gberg_sents, size=64, sg=1, window=10, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('raw_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly load word2vec model if once trained earlier\n",
    "# model = gensim.models.Word2Vec.load('raw_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24155852,  0.01143496, -0.15651083,  0.7529386 ,  0.5278902 ,\n",
       "       -0.12700784, -0.01308403,  0.16439119,  0.29087836,  0.02122007,\n",
       "       -0.24385881,  0.20948479,  0.16510497, -0.17004658, -0.1073853 ,\n",
       "       -0.15149888, -0.3788787 ,  0.41137156,  0.12299947, -0.13052063,\n",
       "        0.35860765, -0.05441206,  0.43108007, -0.07733711, -0.19946651,\n",
       "       -0.11512787,  0.34954023, -0.5238106 ,  0.27686164, -0.09644779,\n",
       "       -0.47463858, -0.3191551 , -0.39529642, -0.46911582, -0.01448686,\n",
       "       -0.4790792 ,  0.06148075,  0.5516783 , -0.18234493, -0.42546907,\n",
       "       -0.07076983,  0.10356606, -0.5772108 , -0.14470063,  0.24906489,\n",
       "       -0.01345674,  0.15924561,  0.2899763 , -0.05688449,  0.18816447,\n",
       "        0.25294244,  0.04539469, -0.3316761 , -0.11860254, -0.1670751 ,\n",
       "        0.06827287, -0.17810197, -0.06937368, -0.16816838,  0.31277075,\n",
       "        0.54932326, -0.4027339 ,  0.33723488, -0.23540972], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('puppy', 0.82535719871521),\n",
       " ('cage', 0.7906226515769958),\n",
       " ('chimney', 0.7856542468070984),\n",
       " ('whip', 0.7672315835952759),\n",
       " ('broth', 0.7647253274917603),\n",
       " ('sweeper', 0.7593879699707031),\n",
       " ('kick', 0.7547622919082642),\n",
       " ('boy', 0.752352237701416),\n",
       " ('thief', 0.7499885559082031),\n",
       " ('wid', 0.7495075464248657)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numbers represent distance \n",
    "model.wv.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lohith\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"mother father daughter dog\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45749652"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('father', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
